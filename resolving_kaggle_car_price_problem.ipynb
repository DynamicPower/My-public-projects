{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85cf4ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import cifar10\n",
    "\n",
    "# Load the CIFAR-10 dataset\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "# Print the dimensions of the training and test images\n",
    "print('Training images shape:', x_train.shape)\n",
    "print('Test images shape:', x_test.shape)\n",
    "\n",
    "# Print the dimensions of the training and test output labels\n",
    "print('Training labels shape:', y_train.shape)\n",
    "print('Test labels shape:', y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae7820d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import cifar10\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the CIFAR-10 dataset\n",
    "(x_train_full, y_train_full), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "# Split the training data into training and validation sets\n",
    "val_ratio = 0.15\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train_full, y_train_full, test_size=val_ratio, random_state=42)\n",
    "\n",
    "# Print the number of samples in each set\n",
    "print('Training samples:', len(x_train))\n",
    "print('Validation samples:', len(x_val))\n",
    "print('Test samples:', len(x_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0210a6d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# it could be:\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b2d355",
   "metadata": {},
   "outputs": [],
   "source": [
    "#To use categorical_crossentropy:\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "# Load the CIFAR-10 dataset\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "# One-hot encode the output labels\n",
    "num_classes = 10\n",
    "y_train_onehot = to_categorical(y_train, num_classes)\n",
    "y_test_onehot = to_categorical(y_test, num_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ba3295",
   "metadata": {},
   "outputs": [],
   "source": [
    "#A more complete code now is:\n",
    "\n",
    "import tensorflow.keras as keras\n",
    "import numpy as np\n",
    "\n",
    "# Load the CIFAR-10 dataset\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()\n",
    "\n",
    "# Convert the labels to one-hot encoded format\n",
    "y_train_onehot = keras.utils.to_categorical(y_train, num_classes=10)\n",
    "y_test_onehot = keras.utils.to_categorical(y_test, num_classes=10)\n",
    "\n",
    "# Flatten the input data\n",
    "x_train = x_train.reshape(x_train.shape[0], -1)\n",
    "x_test = x_test.reshape(x_test.shape[0], -1)\n",
    "\n",
    "# Define the model architecture\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=(3072,)))\n",
    "model.add(keras.layers.Dense(units=256, activation='relu'))\n",
    "model.add(keras.layers.Dense(units=128, activation='relu'))\n",
    "model.add(keras.layers.Dense(units=10, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model on the training data\n",
    "model.fit(x_train, y_train_onehot, batch_size=128, epochs=10, validation_data=(x_test, y_test_onehot))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "258d6fab",
   "metadata": {},
   "source": [
    "#I define a simple neural network architecture with two hidden layers, one flatten and an output layer that has 10 neurons,\n",
    "#one for each class, using CategoricalCrossentropy as the loss function for the last layer and train\n",
    "the model on the one-hot encoded output labels (y_train_onehot) using the fit() method.\n",
    "when we use one-hot encode for the output labels, the dimensions of the output labels will change from (n_samples, 1)\n",
    "to (n_samples, n_classes), where n_samples is the number of samples in the dataset and n_classes is the number of classes. \n",
    "In the case of CIFAR-10, the dimensions of the output labels will change from (n_samples, 1) to (n_samples, 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d41ac850",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a network with five hidden layers to predict the outputs of this dataset.\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "\n",
    "# Load the dataset and preprocess it\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "x_train = x_train / 255.0\n",
    "x_test = x_test / 255.0\n",
    "y_train = keras.utils.to_categorical(y_train)\n",
    "y_test = keras.utils.to_categorical(y_test)\n",
    "\n",
    "# Define the neural network architecture\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(64, activation='relu'),\n",
    "    keras.layers.Dense(32, activation='relu'),\n",
    "    keras.layers.Dense(16, activation='relu'),\n",
    "    keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model on the training data\n",
    "model.fit(x_train, y_train, batch_size=128, epochs=10, validation_data=(x_test, y_test))\n",
    "\n",
    "# Evaluate the performance of the model on the testing data\n",
    "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
    "print('Test accuracy:', test_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b91fde42",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Optimize the hyperparameters of the built model\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from kerastuner.tuners import RandomSearch\n",
    "from keras.layers import Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Load the CIFAR-10 dataset\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()\n",
    "\n",
    "# Convert the labels to one-hot encoded format\n",
    "y_train_onehot = keras.utils.to_categorical(y_train, num_classes=10)\n",
    "y_test_onehot = keras.utils.to_categorical(y_test, num_classes=10)\n",
    "\n",
    "# Define the model-building function\n",
    "def build_model(hp):\n",
    "    model = Sequential([\n",
    "        Flatten(input_shape=(32, 32, 3)),\n",
    "        Dense(units=hp.Int('units', min_value=32, max_value=512, step=32), activation='relu'),\n",
    "        # Add more layers as needed\n",
    "        Dense(10, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    model.compile(optimizer=Adam(learning_rate=hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])),\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "    \n",
    "    # Add hidden layers\n",
    "    for i in range(hp.Int('num_layers', 1, 5)):\n",
    "        model.add(layers.Dense(units=hp.Int(f'units_{i}', min_value=32, max_value=512, step=32), activation='relu'))\n",
    "    \n",
    "    model.add(layers.Dense(units=10, activation='softmax'))\n",
    "    \n",
    "    # Compile the model\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(\n",
    "            hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])),\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Instantiate the tuner and perform the search\n",
    "tuner = RandomSearch(\n",
    "    build_model,\n",
    "    objective='val_accuracy',\n",
    "    max_trials=3,\n",
    "    executions_per_trial=1,\n",
    "    directory='my_dir',\n",
    "    project_name='cifar10_tuning')\n",
    "\n",
    "tuner.search(x=x_train, y=y_train_onehot, epochs=10, validation_data=(x_test, y_test_onehot))\n",
    "\n",
    "# Print the best model's summary\n",
    "tuner.results_summary()\n",
    "best_model = tuner.get_best_models(num_models=1)[0]\n",
    "best_model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70b9081d",
   "metadata": {},
   "source": [
    "Please note I intentinally reduce the max_trials to 3 to code to be runnable, I know it should be a higher number\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8479383a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train the same process with mnist. as it is easier\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Load the MNIST dataset\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "# Normalize the pixel values\n",
    "X_train = X_train.astype('float32') / 255.0\n",
    "X_test = X_test.astype('float32') / 255.0\n",
    "\n",
    "# One-hot encode the target variables\n",
    "num_classes = 10\n",
    "y_train = to_categorical(y_train, num_classes)\n",
    "y_test = to_categorical(y_test, num_classes)\n",
    "\n",
    "# Define the model\n",
    "model = Sequential([\n",
    "    Flatten(input_shape=(28, 28)),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=10, validation_split=0.1)\n",
    "\n",
    "# Define a function to evaluate the model on accuracy, F1 score, and ROC AUC score\n",
    "def evaluate_model(model, X, y):\n",
    "    y_pred = model.predict(X)\n",
    "    y_pred_labels = np.argmax(y_pred, axis=1)\n",
    "    y_true_labels = np.argmax(y, axis=1)\n",
    "    acc = accuracy_score(y_true_labels, y_pred_labels)\n",
    "    f1 = f1_score(y_true_labels, y_pred_labels, average='weighted')\n",
    "    y_pred_prob = model.predict(X)\n",
    "    roc_auc = roc_auc_score(y, y_pred_prob, average='weighted', multi_class='ovo')\n",
    "    return acc, f1, roc_auc\n",
    "\n",
    "# Evaluate the model on the train, validation, and test data\n",
    "train_acc, train_f1, train_roc_auc = evaluate_model(model, X_train, y_train)\n",
    "val_acc, val_f1, val_roc_auc = evaluate_model(model, X_test, y_test)\n",
    "test_acc, test_f1, test_roc_auc = evaluate_model(model, X_test, y_test)\n",
    "\n",
    "print('Train Accuracy:', train_acc)\n",
    "print('Train F1 Score:', train_f1)\n",
    "print('Train ROC AUC Score:', train_roc_auc)\n",
    "print('Validation Accuracy:', val_acc)\n",
    "print('Validation F1 Score:', val_f1)\n",
    "print('Validation ROC AUC Score:', val_roc_auc)\n",
    "print('Test Accuracy:', test_acc)\n",
    "print('Test F1 Score:', test_f1)\n",
    "print('Test ROC AUC Score:', test_roc_auc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32678d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create a dictionary with the evaluation metrics\n",
    "metrics_dict = {\n",
    "    'Accuracy': [train_acc, val_acc, test_acc],\n",
    "    'F1 Score': [train_f1, val_f1, test_f1],\n",
    "    'ROC AUC Score': [train_roc_auc, val_roc_auc, test_roc_auc]\n",
    "}\n",
    "\n",
    "# Create a pandas DataFrame with the dictionary\n",
    "df_metrics = pd.DataFrame(metrics_dict, index=['Train', 'Validation', 'Test'])\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df_metrics)\n",
    "df_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c158199",
   "metadata": {},
   "outputs": [],
   "source": [
    "#writing the accuracy, f1-score, roc_auc, finding code on cifar10 now:\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Load the CIFAR-10 dataset\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "\n",
    "# Normalize the pixel values\n",
    "X_train = X_train.astype('float32') / 255.0\n",
    "X_test = X_test.astype('float32') / 255.0\n",
    "\n",
    "# One-hot encode the target variables\n",
    "num_classes = 10\n",
    "y_train = to_categorical(y_train, num_classes)\n",
    "y_test = to_categorical(y_test, num_classes)\n",
    "\n",
    "# Define the model\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3,3), activation='relu', padding='same', input_shape=(32,32,3)),\n",
    "    MaxPooling2D((2,2)),\n",
    "    Conv2D(64, (3,3), activation='relu', padding='same'),\n",
    "    MaxPooling2D((2,2)),\n",
    "    Conv2D(128, (3,3), activation='relu', padding='same'),\n",
    "    MaxPooling2D((2,2)),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=10, validation_split=0.1)\n",
    "\n",
    "# Define a function to evaluate the model on accuracy, F1 score, and ROC AUC score\n",
    "def evaluate_model(model, X_test, y_test):\n",
    "    y_pred_probs = model.predict(X_test)\n",
    "    y_pred_labels = np.argmax(y_pred_probs, axis=1)\n",
    "    y_true_labels = np.argmax(y_test, axis=1)\n",
    "    acc = accuracy_score(y_true_labels, y_pred_labels)\n",
    "    f1 = f1_score(y_true_labels, y_pred_labels, average='weighted')\n",
    "    roc_auc = roc_auc_score(y_test, y_pred_probs, average='macro', multi_class='ovo')\n",
    "    return acc, f1, roc_auc, y_true_labels, y_pred_labels\n",
    "\n",
    "# Evaluate the model\n",
    "acc, f1, roc_auc, y_true_labels, y_pred_labels = evaluate_model(model, X_test, y_test)\n",
    "print(\"Accuracy: {:.4f}, F1 score: {:.4f}, ROC AUC score: {:.4f}\".format(acc, f1, roc_auc))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a71d94b",
   "metadata": {},
   "source": [
    "As it was difficult to run this code on my computer becuase lack of space, I did it on colab abd put results here:\n",
    "\n",
    "Accuracy: 0.7203\n",
    "\n",
    "F1 score: 0.7182 \n",
    "\n",
    "ROC AUC score: 0.9584"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d066410d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Wide and deep model:\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.layers import Input, Dense, Flatten, Concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Load the CIFAR-10 dataset\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "\n",
    "# Normalize the pixel values\n",
    "X_train = X_train.astype('float32') / 255.0\n",
    "X_test = X_test.astype('float32') / 255.0\n",
    "\n",
    "# One-hot encode the target variables\n",
    "num_classes = 10\n",
    "y_train = to_categorical(y_train, num_classes)\n",
    "y_test = to_categorical(y_test, num_classes)\n",
    "\n",
    "# Define the wide and deep network architecture\n",
    "input_layer = Input(shape=(32, 32, 3))\n",
    "flatten_layer = Flatten()(input_layer)\n",
    "wide_layer = Dense(128, activation='relu')(flatten_layer)\n",
    "deep_layer_1 = Dense(256, activation='relu')(flatten_layer)\n",
    "deep_layer_2 = Dense(128, activation='relu')(deep_layer_1)\n",
    "deep_layer_3 = Dense(64, activation='relu')(deep_layer_2)\n",
    "concat_layer = Concatenate()([wide_layer, deep_layer_3])\n",
    "output_layer = Dense(num_classes, activation='softmax')(concat_layer)\n",
    "\n",
    "model = Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.1)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred_probs = model.predict(X_test)\n",
    "y_pred_labels = np.argmax(y_pred_probs, axis=1)\n",
    "y_true_labels = np.argmax(y_test, axis=1)\n",
    "acc = accuracy_score(y_true_labels, y_pred_labels)\n",
    "f1 = f1_score(y_true_labels, y_pred_labels, average='weighted')\n",
    "roc_auc = roc_auc_score(y_true_labels, y_pred_labels, average='macro', multi_class='ovo')\n",
    "print(\"Wide and deep network accuracy: {:.3f}\".format(acc))\n",
    "print(\"Wide and deep network F1 score: {:.3f}\".format(f1))\n",
    "print(\"Wide and deep network ROC AUC score: {:.3f}\".format(roc_auc))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9863063",
   "metadata": {},
   "source": [
    "As it was difficult to run this code on my computer becuase lack of space, I did it on colab abd put results here:\n",
    "\n",
    "Wide and deep network accuracy: 0.694\n",
    "\n",
    "Wide and deep network F1 score: 0.692\n",
    "\n",
    "Wide and deep network ROC AUC score: 0.825\n",
    "\n",
    "In comparison to the previous step's deep network, the broad and deep network obtains slightly higher accuracy and F1 score but significantly lower ROC AUC score. However, because the changes between the two models are minor, it is feasible that their performance is equivalent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e54a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install sklearn_genetic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "413be542",
   "metadata": {},
   "outputs": [],
   "source": [
    "#optimize the parameters of the previously defined model using the sklearn_genetic library:\n",
    "import sklearn_genetic\n",
    "from sklearn_genetic import GASearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "  \n",
    "\n",
    "# Define the function to create the Keras model\n",
    "def create_model(optimizer='adam', activation='relu', dropout_rate=0.2):\n",
    "    model = Sequential([\n",
    "        Flatten(input_shape=(32, 32, 3)),\n",
    "        Dense(128, activation=activation),\n",
    "        Dropout(dropout_rate),\n",
    "        Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Wrap the Keras model with the scikit-learn API\n",
    "keras_clf = KerasClassifier(build_fn=create_model, epochs=10, batch_size=64, verbose=0)\n",
    "\n",
    "# Define the parameter space to be searched\n",
    "params = {\n",
    "    'optimizer': ['adam', 'sgd'],\n",
    "    'activation': ['relu', 'sigmoid'],\n",
    "    'dropout_rate': [0.2, 0.4, 0.6]\n",
    "}\n",
    "\n",
    "# Create the genetic algorithm search object\n",
    "ga_search = GASearchCV(estimator=keras_clf, cv=StratifiedKFold(), scoring='accuracy', n_population=10, \n",
    "                       generations_number=5, params=params)\n",
    "\n",
    "# Fit the genetic algorithm search object to the data\n",
    "ga_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters found\n",
    "print(\"Best parameters found: \", ga_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c676df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from kerastuner.tuners import RandomSearch\n",
    "import time\n",
    "\n",
    "# Load the dataset and preprocess it\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "x_train = x_train / 255.0\n",
    "x_test = x_test / 255.0\n",
    "y_train = keras.utils.to_categorical(y_train)\n",
    "y_test = keras.utils.to_categorical(y_test)\n",
    "\n",
    "# Define the neural network architecture\n",
    "def build_model(hp):\n",
    "    model = keras.Sequential()\n",
    "    model.add(layers.Conv2D(filters=hp.Int('conv1_filters', min_value=32, max_value=256, step=32),\n",
    "                            kernel_size=hp.Choice('conv1_kernel', values=[3, 5]),\n",
    "                            activation='relu',\n",
    "                            input_shape=(32, 32, 3)))\n",
    "    model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(layers.Conv2D(filters=hp.Int('conv2_filters', min_value=32, max_value=256, step=32),\n",
    "                            kernel_size=hp.Choice('conv2_kernel', values=[3, 5]),\n",
    "                            activation='relu'))\n",
    "    model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(units=hp.Int('dense1_units', min_value=32, max_value=512, step=32),\n",
    "                           activation='relu'))\n",
    "    model.add(layers.Dropout(rate=hp.Float('dropout1', min_value=0.0, max_value=0.5, step=0.1)))\n",
    "    model.add(layers.Dense(10, activation='softmax'))\n",
    "    model.compile(optimizer=keras.optimizers.Adam(hp.Float('learning_rate', min_value=1e-4, max_value=1e-2, sampling='log')),\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Create a Keras tuner object and define the search space\n",
    "tuner = RandomSearch(\n",
    "    build_model,\n",
    "    objective='val_accuracy',\n",
    "    max_trials=5,\n",
    "    executions_per_trial=1,\n",
    "    directory='tuner_dir',\n",
    "    project_name='cifar10_cnn')\n",
    "\n",
    "# Define the early stopping callback\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=3)\n",
    "\n",
    "# Start the hyperparameter search\n",
    "start_time = time.time()\n",
    "tuner.search(x_train, y_train, epochs=5, validation_data=(x_test, y_test), callbacks=[early_stop])\n",
    "end_time = time.time()\n",
    "\n",
    "# Print the best results\n",
    "best_model = tuner.get_best_models(num_models=1)[0]\n",
    "test_loss, test_acc = best_model.evaluate(x_test, y_test)\n",
    "print('Best model:')\n",
    "best_model.summary()\n",
    "print('Test accuracy:', test_acc)\n",
    "\n",
    "# Print the elapsed time\n",
    "elapsed_time = end_time - start_time\n",
    "print('Elapsed time:', elapsed_time, 'seconds')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cfb5800",
   "metadata": {},
   "outputs": [],
   "source": [
    "#after running above code, we obtained best hyperparameters and rewite the code:\n",
    "#Best learning rate: 0.0008793685539613403\n",
    "#Best conv1_filters: 64\n",
    "#Best conv1_kernel: 5\n",
    "#Best conv2_filters: 32\n",
    "#Best conv2_kernel: 3\n",
    "#Best dense1_units: 480\n",
    "#Best dropout1: 0.4\n",
    "    \n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "\n",
    "# Load the dataset and preprocess it\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "x_train = x_train / 255.0\n",
    "x_test = x_test / 255.0\n",
    "y_train = keras.utils.to_categorical(y_train)\n",
    "y_test = keras.utils.to_categorical(y_test)\n",
    "\n",
    "# Define the neural network architecture with the best hyperparameters\n",
    "model = keras.Sequential()\n",
    "model.add(layers.Conv2D(filters=64, kernel_size=5, activation='relu', input_shape=(32, 32, 3)))\n",
    "model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(layers.Conv2D(filters=32, kernel_size=3, activation='relu'))\n",
    "model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(units=480, activation='relu'))\n",
    "model.add(layers.Dropout(rate=0.4))\n",
    "model.add(layers.Dense(10, activation='softmax'))\n",
    "model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.0001),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(x_train, y_train, epochs=100, validation_data=(x_test, y_test))\n",
    "\n",
    "# Evaluate the model\n",
    "acc, f1, roc_auc, y_true_labels, y_pred_labels = evaluate_model(model, x_test, y_test)\n",
    "print(\"Accuracy: {:.4f}, F1 score: {:.4f}, ROC AUC score: {:.4f}\".format(acc, f1, roc_auc))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
